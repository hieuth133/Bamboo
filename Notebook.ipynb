{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notebook.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMbAel1OAVbs2iDR7BQIdEd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Gl998OZ9G6rZ"},"source":["## Import Drive"]},{"cell_type":"code","metadata":{"id":"oo__LXbVG4sx"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P36QX8hpG_GE"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"uD9IH7VouF9Y"},"source":["%%capture\n","import tensorflow.keras\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose, ZeroPadding2D\n","from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization,Reshape\n","from tensorflow.keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU, Multiply, add,multiply\n","from tensorflow.keras.utils import plot_model\n","from IPython.display import SVG\n","from tensorflow.keras.utils import model_to_dot\n","import pickle\n","from time import time\n","import shutil\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from tensorflow.python.framework import graph_util\n","tf.compat.v1.disable_eager_execution()\n","from tensorflow.keras.optimizers import Adam, RMSprop,SGD\n","import glob\n","from numpy import expand_dims\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import array_to_img\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from matplotlib import pyplot as plt\n","import random\n","from tensorflow.keras.models import model_from_json\n","from tensorflow.keras.optimizers import Adam, RMSprop,SGD"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBvAYoZRHEly"},"source":["## MDenseNet - keras version"]},{"cell_type":"code","metadata":{"id":"B8iTQQ77HFrw"},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os\n","\n","from keras.applications import imagenet_utils\n","from keras.applications.imagenet_utils import decode_predictions\n","\n","\n","def dense_block(x, blocks, name):\n","\n","    for i in range(blocks):\n","        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n","    return x\n","\n","\n","def transition_block(x, reduction, name):\n","\n","    bn_axis = 3\n","    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n","                                  name=name + '_bn')(x)\n","    x = Activation('relu', name=name + '_relu')(x)\n","    x = Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1,\n","                      use_bias=False,\n","                      name=name + '_conv')(x)\n","    x = AvgPool2D(2, strides=2, name=name + '_pool')(x)\n","    return x\n","\n","def add_block(_x1,_x2):\n","    # print('_x1',K.int_shape(_x1))\n","    # print('_x2',K.int_shape(_x2))\n","    size = int(K.int_shape(_x1)[1] / K.int_shape(_x2)[1])\n","    _x2 = UpSampling2D(size=(size,size))(_x2)\n","    sc = Conv2D(K.int_shape(_x2)[-1], 1, strides=1,padding='same')(_x1)\n","    sc = BatchNormalization()(sc)\n","    output = Add()([_x2,sc])\n","    output = ReLU()(output)\n","    output = MaxPool2D(size,padding='same')(output)\n","    # print('output',K.int_shape(output))\n","    return output\n","\n","def conv_block(x, growth_rate, name):\n","    bn_axis = 3\n","    x1 = BatchNormalization(axis=bn_axis,\n","                                   epsilon=1.001e-5,\n","                                   name=name + '_0_bn')(x)\n","    x1 = ReLU()(x1)\n","    x1 = Conv2D(4 * growth_rate, 1,\n","                       use_bias=False,\n","                       name=name + '_1_conv')(x1)\n","    x1 = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n","                                   name=name + '_1_bn')(x1)\n","    x1 = ReLU()(x1)\n","    x1 = SeparableConv2D(growth_rate, 3,\n","                       padding='same',\n","                       use_bias=False,\n","                       name=name + '_2_conv')(x1)\n","    x = Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n","    return x\n","\n","\n","def DenseNet(blocks,\n","             include_top=True,\n","             weights='imagenet',\n","             input_tensor=None,\n","             input_shape=None,\n","             pooling=None,\n","             classes=1000,\n","             **kwargs):\n","\n","    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization), `imagenet` '\n","                         '(pre-training on ImageNet), '\n","                         'or the path to the weights file to be loaded.')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not backend.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    bn_axis = 3 \n","\n","    x = ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n","    x = Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n","    x = BatchNormalization(\n","        axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(x)\n","    x = ReLU()(x)\n","    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n","    x0 = MaxPool2D(3, strides=2, name='pool1')(x)\n","\n","    # if abs == True:\n","    x1 = dense_block(x0, blocks[0], name='conv2')\n","    x1 = transition_block(x1, 0.5, name='pool2')\n","    x1 = add_block(x0,x1)\n","\n","    x2 = dense_block(x1, blocks[1], name='conv3')\n","    x2 = transition_block(x2, 0.5, name='pool3')\n","    x2 = add_block(x0,x2)\n","    x2 = add_block(x1,x2)\n","\n","    x3 = dense_block(x2, blocks[2], name='conv4')\n","    x3 = transition_block(x3, 0.5, name='pool4')\n","    x3 = add_block(x0,x3)\n","    x3 = add_block(x1,x3)\n","    x = add_block(x2,x3)\n","\n","    x = dense_block(x, blocks[3], name='conv5')\n","\n","\n","    x = BatchNormalization(\n","        axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n","    x = Activation('relu', name='relu')(x)\n","\n","    x = GlobalAvgPool2D(name='avg_pool')(x)\n","    x = Dense(classes, activation='softmax', name='fc'+str(classes))(x)\n","\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = keras_utils.get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","\n","    # Create model.\n","    if blocks == [6, 12, 24, 16]:\n","        model = Model(inputs, x, name='densenet121abs')\n","    elif blocks == [6, 12, 32, 32]:\n","        model = Model(inputs, x, name='densenet169abs')\n","    elif blocks == [6, 12, 48, 32]:\n","        model = Model(inputs, x, name='densenet201abs')\n","    else:\n","        model = Model(inputs, x, name='densenetabs')\n","    return model\n","\n","\n","def DenseNet121abs(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000,\n","                \n","                **kwargs):\n","    return DenseNet([6, 12, 24, 16],\n","                    include_top, weights,\n","                    input_tensor, input_shape,\n","                    pooling, classes,\n","                    **kwargs)\n","\n","\n","def DenseNet169abs(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000,\n","                \n","                **kwargs):\n","    return DenseNet([6, 12, 32, 32],\n","                    include_top, weights,\n","                    input_tensor, input_shape,\n","                    pooling, classes, \n","                    **kwargs)\n","\n","\n","def DenseNet201abs(include_top=True,\n","                weights='imagenet',\n","                input_tensor=None,\n","                input_shape=None,\n","                pooling=None,\n","                classes=1000,\n","                \n","                **kwargs):\n","    return DenseNet([6, 12, 48, 32],\n","                    include_top, weights,\n","                    input_tensor, input_shape,\n","                    pooling, classes,\n","                    **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mR72nkxgHPUr"},"source":["## DenseNet - origin keras version"]},{"cell_type":"code","metadata":{"id":"VHzIXPAgHO-b"},"source":["def densenet_keras(n_conv,weights = None ,input_shape = (224,224,3)):\n","  '''n_conv: number of conv layer: 121, 169 or 201\n","      weights: None or 'Imagenet'\n","      input_shape: tuple example (224,224,3)'''\n","  if n_conv == 121:\n","    modeltest = tensorflow.keras.applications.DenseNet121(include_top=False, weights=weights, input_shape=input_shape)\n","  elif n_conv == 169:\n","    modeltest = tensorflow.keras.applications.DenseNet169(include_top=False, weights=weights, input_shape=input_shape)\n","  elif n_conv == 201:\n","    modeltest = tensorflow.keras.applications.DenseNet201(include_top=False, weights=weights, input_shape=input_shape)\n","  # # modeltest.summary()\n","  x = GlobalAvgPool2D()(modeltest.output)\n","  output = Dense(n_classes,activation='softmax')(x)\n","  model = Model(modeltest.input, output,name = modeltest.name+'_norm')\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4skXcj_HJ8R"},"source":["input_shape = 224,224,3\n","\n","n_classes = 100 # 7 if using bamboo dataset\n","K.clear_session()\n","global graph\n","\n","# Model Densenet121abs, Densenet169abs, Densenet201abs\n","model = DenseNet121abs(include_top=False,weights=None,input_shape=(224,224,3),classes=n_classes)\n","print('Model name: {}\\nModel params: {} '.format(model.name, model.count_params()))\n","\n","# Calculate FLOPs\n","input = np.random.randn(1, *input_shape)\n","graph = tf.compat.v1.get_default_graph()\n","sess = tf.compat.v1.Session(graph=graph)\n","model._make_predict_function()\n","sess.run(tf.compat.v1.global_variables_initializer())\n","flops = tf.compat.v1.profiler.profile(graph, options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation())\n","print(model.name,' FLOP = ', flops.total_float_ops)\n","\n","sgd = SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n","adam = Adam(lr=0.001)\n","rmsp = RMSprop(lr=0.1)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3DzxGHyIn8V"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"rA4TeJL2Hpv3"},"source":["from zipfile import ZipFile\n","\n","def extract(file_name_data,fp='data'):\n","  with ZipFile(file_name_data,'r') as zip:\n","    zip.extractall(fp)\n","\n","# For bamboo dataset\n","# extract('/content/drive/MyDrive/dataset/DATA.zip')\n","\n","# For mini-imagenet\n","extract('/content/drive/My Drive/Slice-ImageNet/Tiny-ImageNet2.zip','mini-imagenet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLtkPHVDIphN"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","BATCH_SIZE = 32\n","TARGET_SIZE = (224,224)\n","root = '/content/tiny-imagenet2/Tiny-ImageNet2'\n","train_root = '/content/tiny-imagenet2/Tiny-ImageNet2/train'\n","val_root = '/content/tiny-imagenet2/Tiny-ImageNet2/val'\n","\n","\n","datagen = ImageDataGenerator(rescale= 1./255)\n","\n","#For img data folder\n","generator_train = datagen.flow_from_directory(\n","        train_root,\n","        target_size=TARGET_SIZE,\n","        batch_size=BATCH_SIZE,\n","        interpolation=\"nearest\")\n","generator_valid = datagen.flow_from_directory(\n","        val_root,\n","        target_size=TARGET_SIZE,\n","        batch_size=BATCH_SIZE,\n","        interpolation=\"nearest\")\n","\n","steps_per_epoch = int(generator_train.n / BATCH_SIZE)\n","steps_valid = (generator_valid.n) // BATCH_SIZE\n","class_names = os.listdir(train_root)\n","class_names.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ufke_cCSIwYc"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"rGs5yN8rIu_E"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping,ReduceLROnPlateau\n","\n","def lr_schedule(epoch):\n","    \"\"\"Learning Rate Schedule\n","\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n","    Called automatically every epoch as part of callbacks during training.\n","\n","    # Arguments\n","        epoch (int): The number of epochs\n","\n","    # Returns\n","        lr (float32): learning rate\n","    \"\"\"\n","    lr = 1e-3\n","    if epoch > 100:\n","        lr *= 0.5e-3\n","    elif epoch > 30:\n","        lr *= 1e-3\n","    elif epoch > 20:\n","        lr *= 1e-2\n","    elif epoch > 10:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=3,\n","                               min_lr=0.5e-6)\n","model_save_path = '/content/drive/My Drive/Slice-ImageNet'\n","model_name = model.name + '.hdf5'\n","model_path = os.path.join(model_save_path,model_name)\n","earlyStopping = EarlyStopping(monitor = 'val_loss',min_delta = 0,patience = 10,restore_best_weights = True)\n","mcp_save = ModelCheckpoint(model_path,monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n","callbacks = [mcp_save,lr_scheduler,lr_reducer]\n","# callbacks = [mcp_save]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjZGjG4tI0oA"},"source":["epochs1 = 30\n","print(model.name)\n","history0 = model.fit_generator(generator= generator_train,\n","                                   steps_per_epoch = steps_per_epoch,\n","                                   validation_data=generator_valid,\n","                                   epochs=epochs1, verbose=1, workers=1, validation_steps=steps_valid,\n","                                   callbacks=callbacks, use_multiprocessing=False)\n","with open(os.path.join('/content/drive/My Drive/Slice-ImageNet', model.name +'.pkl'), 'wb') as fp:\n","  pickle.dump(history0.history,fp,protocol=pickle.HIGHEST_PROTOCOL)\n","model_json = model.to_json()\n","with open(os.path.join('/content/drive/My Drive/Slice-ImageNet',model.name+'.json'), 'w') as json_file:\n","  json_file.write(model_json)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzM-hW0YI2Go"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"KoWA5ajoI3Cg"},"source":["import matplotlib.pyplot as plt\n","plt.rcParams['figure.figsize'] = (16.0, 12.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n"," \n","def plot_training_history(history):\n","    plt.subplot(2, 1, 1)\n","    # Plot training & validation accuracy values\n","    plt.plot(history.history['categorical_accuracy'])\n","    plt.plot(history.history['val_categorical_accuracy'])\n","    plt.title('Model accuracy '+model.name)\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()\n","\n","\n","    # Plot training & validation loss values\n","    plt.subplot(2, 1, 1)\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()\n","plot_training_history(history0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28hmadfpI68c"},"source":["import matplotlib.pyplot as plt\n","plt.rcParams['figure.figsize'] = (16.0, 12.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","def predict(loaded_model,img_dirs):\n","  count = 0\n","  for img_dir in img_dirs:\n","    img = image.load_img(img_dir, target_size= (224, 224))\n","    img = image.img_to_array(img)\n","    img /= 255\n","    img = np.expand_dims(img,axis=0)\n","    y_pred = loaded_model.predict(img)\n","    cls_pred = np.argmax(y_pred, axis=1)\n","    cls_pred = int(cls_pred[0])\n","    # print(cls_pred)\n","    class_predict = class_names[cls_pred]\n","    if class_predict in img_dir:\n","      count += 1\n","  return ((count/200) * 100)\n","def load_file(file_path):\n","  f = open(file_path,'rb')\n","  return f\n","def compareHis(arrHis,h1,h2):\n","    plt.subplot(2, 1, 1)\n","    # Plot validation accuracy values\n","    for history in arrHis:\n","      plt.plot(history['val_categorical_accuracy'])\n","    plt.title('Model accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend([h1, h2], loc='upper left')\n","    plt.show()\n","\n","    # Plot validation loss values\n","    plt.subplot(2, 1, 1)\n","    for history in arrHis:\n","      plt.plot(history['val_loss'])\n","    plt.title('Model loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend([h1, h2], loc='upper left')\n","    plt.show()\n","def get_new_model(model_path,json_path):\n","  with open(json_path,'r') as json_file:\n","    loaded_model_json = json_file.read()\n","  json_file.close()\n","  loaded_model = model_from_json(loaded_model_json)\n","  # load weights into new model\n","  loaded_model.load_weights(model_path)\n","  return loaded_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bb6i_ij9I_Cx"},"source":["result = model.evaluate_generator(generator=generator_valid, steps=steps_valid,verbose = 1)\n","print(model.name+\" Valid-set classification accuracy: {0:.2%}\".format(result[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kut50kPLJBVo"},"source":["img_dirs = glob.glob('/content/tiny-imagenet2/Tiny-ImageNet2/test/*.jpg')\n","img_dirs.sort()\n","print(model.name)\n","print(predict(model,img_dirs))"],"execution_count":null,"outputs":[]}]}